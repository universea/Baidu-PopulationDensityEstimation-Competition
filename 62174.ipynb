{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 解压螺丝螺母数据\n",
    "#!cd data/data6045/ && unzip -q lslm.zip && unzip -q lslm-test.zip\n",
    "#!cd data/data1917/ && unzip -q train_new.zip && unzip -q test_new.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据处理成需要的格式：\n",
    "* label_list.txt                             每一行一个类别，类别编号\\t类别名字\n",
    "* train.txt                                    每一行一个样本，图片路径\\t[{\"bbox\":{\"left\":0, \"top\": 0, \"width\":0, \"height\":0}, \"label\": 1}...]\n",
    "* trainImageSet/xxx.jpg             训练图片\n",
    "* eval.txt                                    格式通 train.txt\n",
    "* evalImageSet/xxx.jpg              验证图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len annotations ==  2000\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "train_path = 'dataset/train'\n",
    "#with codecs.open('data/data6045/train.txt', 'w') as f:\n",
    "#    with codecs.open('data/data6045/lslm/train.txt') as r:\n",
    "#        for line in r:\n",
    "#            f.write(train_path + '/' + line)\n",
    "\n",
    "\n",
    "eval_path = 'dataset/test'\n",
    "#with codecs.open('data/data6045/eval.txt', 'w') as f:\n",
    "#    with codecs.open('data/data6045/lslm-test/eval.txt') as r:\n",
    "#        for line in r:\n",
    "#            f.write(eval_path + '/' + line)\n",
    "\n",
    "#if os.path.exists('data/data6045/lslm/label_list.txt'):\n",
    "#    shutil.move('data/data6045/lslm/label_list.txt', 'data/data6045/label_list.txt')\n",
    "#if os.path.exists('data/data6045/lslm/label_list'):\n",
    "#    shutil.move('data/data6045/lslm/label_list', 'data/data6045/label_list')\n",
    "#os.remove('data/data1917/label_list')\n",
    "with codecs.open('label_list', 'w') as f:\n",
    "    f.write(\"person\")\n",
    "\n",
    "i = 0\n",
    "#os.remove('data/data1917/train.txt')\n",
    "with codecs.open('train.txt', 'w',encoding='utf-8-sig') as f:\n",
    "    #f.write(\"person\")\n",
    "    with open('train.json','r') as flist:\n",
    "        jsons = json.load(flist)\n",
    "        print('len annotations == ',len(jsons['annotations']))\n",
    "        for i in range(len(jsons['annotations'])):\n",
    "            if i >= 0:\n",
    "                lingstring = ''\n",
    "                img_path = 'dataset/' + jsons['annotations'][i]['name']\n",
    "                img_path = img_path.replace('/stage1/', '/')\n",
    "                #print(img_path)\n",
    "                type = jsons['annotations'][i]['type']\n",
    "                annotations = jsons['annotations'][i]['annotation']\n",
    "                lingstring += img_path\n",
    "                lingstring += ' '\n",
    "                if type == \"bbox\":\n",
    "                    for annotation in annotations:\n",
    "                        dict = {'value':'person','coordinate':[]}\n",
    "                        #print(dict)\n",
    "                        w = annotation['w']\n",
    "                        h = annotation['h']\n",
    "                        ymin = annotation['y']\n",
    "                        xmin = annotation['x']\n",
    "                        xmax = xmin + w\n",
    "                        ymax = ymin + h\n",
    "                        xymin = [xmin,ymin]\n",
    "                        xymax = [xmax,ymax]\n",
    "                        dict['coordinate'] = [xymin,xymax]\n",
    "                        #print(json.dumps(dict))\n",
    "                        lingstring += json.dumps(dict,separators=(',', ':'))\n",
    "                        lingstring += ' '\n",
    "                else:\n",
    "                    for annotation in annotations:\n",
    "                        dict = {'value':'person','coordinate':[]}\n",
    "                        #print(dict)\n",
    "                        w = 1\n",
    "                        h = 1\n",
    "                        ymin = annotation['y']\n",
    "                        xmin = annotation['x']\n",
    "                        xmax = xmin + w\n",
    "                        ymax = ymin + h\n",
    "                        xymin = [xmin,ymin]\n",
    "                        xymax = [xmax,ymax]\n",
    "                        dict['coordinate'] = [xymin,xymax]\n",
    "                        #print(json.dumps(dict))\n",
    "                        lingstring += json.dumps(dict,separators=(',', ':'))\n",
    "                        lingstring += ' '\n",
    "                #print(lingstring)\n",
    "                lingstring += '\\n'\n",
    "                f.writelines(lingstring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练Yolo-v3模型的配置项，目前暂时没有预训练模型。可以控制是否启用tiny版本，tiny版本体积小，适合部署在移动设备。如果不熟悉，请不要随便更改图片的尺寸和anchors的尺寸，两者相互关联"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-dba0b27a3893>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0muuid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "\"\"\"\n",
    "训练常基于dark-net的YOLOv3网络，目标检测\n",
    "\"\"\"\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import os\n",
    "import uuid\n",
    "import numpy as np\n",
    "import time\n",
    "import six\n",
    "import math\n",
    "import random\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "import logging\n",
    "import xml.etree.ElementTree\n",
    "import codecs\n",
    "import json\n",
    "\n",
    "from paddle.fluid.initializer import MSRA\n",
    "from paddle.fluid.param_attr import ParamAttr\n",
    "from paddle.fluid.regularizer import L2Decay\n",
    "from PIL import Image, ImageEnhance, ImageDraw\n",
    "\n",
    "logger = None\n",
    "train_parameters = {\n",
    "    \"data_dir\": \"dataset/\",\n",
    "    \"file_list\": \"train.txt\",\n",
    "    \"class_dim\": -1,\n",
    "    \"label_dict\": {},\n",
    "    \"image_count\": -1,\n",
    "    \"continue_train\": True,     # 是否加载前一次的训练参数，接着训练\n",
    "    \"pretrained\": False,\n",
    "    \"pretrained_model_dir\": \"./pretrained-model\",\n",
    "    \"save_model_dir\": \"./yolo-model\",\n",
    "    \"model_prefix\": \"yolo-v3\",\n",
    "    \"use_tiny\": False,          # 是否使用 裁剪 tiny 模型\n",
    "    \"max_box_num\": 20,          # 一幅图上最多有多少个目标\n",
    "    \"num_epochs\": 120,\n",
    "    \"train_batch_size\": 5,      # 对于完整 yolov3，每一批的训练样本不能太多，内存会炸掉\n",
    "    \"use_gpu\": True,\n",
    "    \"yolo_cfg\": {\n",
    "        \"input_size\": [3, 608, 608],\n",
    "        \"anchors\": [10, 13,  16, 30,  33, 23,  30, 61,  62, 45,  59, 119,  116, 90,  156, 198,  373, 326],\n",
    "        \"anchor_mask\": [[6, 7, 8], [3, 4, 5], [0, 1, 2]]\n",
    "    },\n",
    "    \"yolo_tiny_cfg\": {\n",
    "        \"input_size\": [3, 256, 256],\n",
    "        \"anchors\": [6, 8, 13, 15, 22, 34, 48, 50, 81, 100, 205, 191],\n",
    "        \"anchor_mask\": [[3, 4, 5], [0, 1, 2]]\n",
    "    },\n",
    "    \"ignore_thresh\": 0.7,\n",
    "    \"mean_rgb\": [127.5, 127.5, 127.5],\n",
    "    \"mode\": \"train\",\n",
    "    \"multi_data_reader_count\": 4,\n",
    "    \"apply_distort\": True,\n",
    "    \"valid_thresh\": 0.01,\n",
    "    \"nms_thresh\": 0.45,\n",
    "    \"image_distort_strategy\": {\n",
    "        \"expand_prob\": 0.5,\n",
    "        \"expand_max_ratio\": 4,\n",
    "        \"hue_prob\": 0.5,\n",
    "        \"hue_delta\": 18,\n",
    "        \"contrast_prob\": 0.5,\n",
    "        \"contrast_delta\": 0.5,\n",
    "        \"saturation_prob\": 0.5,\n",
    "        \"saturation_delta\": 0.5,\n",
    "        \"brightness_prob\": 0.5,\n",
    "        \"brightness_delta\": 0.125\n",
    "    },\n",
    "    \"rsm_strategy\": {\n",
    "        \"learning_rate\": 0.001,\n",
    "        \"lr_epochs\": [20, 40, 60, 80, 100],\n",
    "        \"lr_decay\": [1, 0.5, 0.25, 0.1, 0.05, 0.01],\n",
    "    },\n",
    "    \"momentum_strategy\": {\n",
    "        \"learning_rate\": 0.1,\n",
    "        \"decay_steps\": 2 ** 7,\n",
    "        \"decay_rate\": 0.8\n",
    "    },\n",
    "    \"early_stop\": {\n",
    "        \"sample_frequency\": 50,\n",
    "        \"successive_limit\": 3,\n",
    "        \"min_loss\": 2.5,\n",
    "        \"min_curr_map\": 0.84\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义两个类，分别代表 Yolo-v3 和 Yolo-v3-tiny 两个模型。跟随其后的是模型选择函数，根据配置使用不同的模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class YOLOv3(object):\n",
    "    def __init__(self, class_num, anchors, anchor_mask):\n",
    "        self.outputs = []\n",
    "        self.downsample_ratio = 1\n",
    "        self.anchor_mask = anchor_mask\n",
    "        self.anchors = anchors\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.yolo_anchors = []\n",
    "        self.yolo_classes = []\n",
    "        for mask_pair in self.anchor_mask:\n",
    "            mask_anchors = []\n",
    "            for mask in mask_pair:\n",
    "                mask_anchors.append(self.anchors[2 * mask])\n",
    "                mask_anchors.append(self.anchors[2 * mask + 1])\n",
    "            self.yolo_anchors.append(mask_anchors)\n",
    "            self.yolo_classes.append(class_num)\n",
    "\n",
    "    def name(self):\n",
    "        return 'YOLOv3'\n",
    "\n",
    "    def get_anchors(self):\n",
    "        return self.anchors\n",
    "\n",
    "    def get_anchor_mask(self):\n",
    "        return self.anchor_mask\n",
    "\n",
    "    def get_class_num(self):\n",
    "        return self.class_num\n",
    "\n",
    "    def get_downsample_ratio(self):\n",
    "        return self.downsample_ratio\n",
    "\n",
    "    def get_yolo_anchors(self):\n",
    "        return self.yolo_anchors\n",
    "\n",
    "    def get_yolo_classes(self):\n",
    "        return self.yolo_classes\n",
    "\n",
    "    def conv_bn(self,\n",
    "                input,\n",
    "                num_filters,\n",
    "                filter_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                use_cudnn=True):\n",
    "        conv = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            act=None,\n",
    "            use_cudnn=use_cudnn,\n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "            bias_attr=False)\n",
    "\n",
    "        # batch_norm中的参数不需要参与正则化，所以主动使用正则系数为0的正则项屏蔽掉\n",
    "        # 在batch_norm中使用 leaky 的话，只能使用默认的 alpha=0.02；如果需要设值，必须提出去单独来\n",
    "        out = fluid.layers.batch_norm(\n",
    "            input=conv, act=None, \n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02), regularizer=L2Decay(0.)),\n",
    "            bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "        out = fluid.layers.leaky_relu(out, 0.1)\n",
    "        return out\n",
    "\n",
    "    def downsample(self, input, num_filters, filter_size=3, stride=2, padding=1):\n",
    "        self.downsample_ratio *= 2\n",
    "        return self.conv_bn(input, \n",
    "                num_filters=num_filters, \n",
    "                filter_size=filter_size, \n",
    "                stride=stride, \n",
    "                padding=padding)\n",
    "\n",
    "    def basicblock(self, input, num_filters):\n",
    "        conv1 = self.conv_bn(input, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        conv2 = self.conv_bn(conv1, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        out = fluid.layers.elementwise_add(x=input, y=conv2, act=None)\n",
    "        return out\n",
    "\n",
    "    def layer_warp(self, input, num_filters, count):\n",
    "        res_out = self.basicblock(input, num_filters)\n",
    "        for j in range(1, count):\n",
    "            res_out = self.basicblock(res_out, num_filters)\n",
    "        return res_out\n",
    "\n",
    "    def upsample(self, input, scale=2):\n",
    "        # get dynamic upsample output shape\n",
    "        shape_nchw = fluid.layers.shape(input)\n",
    "        shape_hw = fluid.layers.slice(shape_nchw, axes=[0], starts=[2], ends=[4])\n",
    "        shape_hw.stop_gradient = True\n",
    "        in_shape = fluid.layers.cast(shape_hw, dtype='int32')\n",
    "        out_shape = in_shape * scale\n",
    "        out_shape.stop_gradient = True\n",
    "\n",
    "        # reisze by actual_shape\n",
    "        out = fluid.layers.resize_nearest(\n",
    "            input=input,\n",
    "            scale=scale,\n",
    "            actual_shape=out_shape)\n",
    "        return out\n",
    "    \n",
    "    def yolo_detection_block(self, input, num_filters):\n",
    "        assert num_filters % 2 == 0, \"num_filters {} cannot be divided by 2\".format(num_filters)\n",
    "        conv = input\n",
    "        for j in range(2):\n",
    "            conv = self.conv_bn(conv, num_filters, filter_size=1, stride=1, padding=0)\n",
    "            conv = self.conv_bn(conv, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        route = self.conv_bn(conv, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        tip = self.conv_bn(route, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        return route, tip\n",
    "\n",
    "    def net(self, img): \n",
    "        # darknet\n",
    "        stages = [1,2,8,8,4]\n",
    "        assert len(self.anchor_mask) <= len(stages), \"anchor masks can't bigger than downsample times\"\n",
    "        # 256x256\n",
    "        conv1 = self.conv_bn(img, num_filters=32, filter_size=3, stride=1, padding=1)\n",
    "        downsample_  = self.downsample(conv1, conv1.shape[1] * 2)\n",
    "        blocks = []\n",
    "\n",
    "        for i, stage_count in enumerate(stages):\n",
    "            block = self.layer_warp(downsample_, 32 *(2**i), stage_count)\n",
    "            blocks.append(block)\n",
    "            if i < len(stages) - 1:\n",
    "                downsample_ = self.downsample(block, block.shape[1]*2)\n",
    "        blocks = blocks[-1:-4:-1]   # 取倒数三层，并且逆序，后面跨层级联需要\n",
    "\n",
    "        # yolo detector\n",
    "        for i, block in enumerate(blocks):\n",
    "            # yolo 中跨视域链接\n",
    "            if i > 0:\n",
    "                block = fluid.layers.concat(input=[route, block], axis=1)\n",
    "            route, tip = self.yolo_detection_block(block, num_filters=512 // (2**i))\n",
    "            block_out = fluid.layers.conv2d(\n",
    "                input=tip,\n",
    "                num_filters=len(self.anchor_mask[i]) * (self.class_num + 5),      # 5 elements represent x|y|h|w|score\n",
    "                filter_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                act=None,\n",
    "                param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "                bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "            self.outputs.append(block_out)\n",
    "            # 为了跨视域链接，差值方式提升特征图尺寸\n",
    "            if i < len(blocks) - 1:\n",
    "                route = self.conv_bn(route, 256//(2**i), filter_size=1, stride=1, padding=0)\n",
    "                route = self.upsample(route)\n",
    "\n",
    "        return self.outputs\n",
    "\n",
    "\n",
    "class YOLOv3Tiny(object):\n",
    "    def __init__(self, class_num, anchors, anchor_mask):\n",
    "        self.outputs = []\n",
    "        self.downsample_ratio = 1\n",
    "        self.anchor_mask = anchor_mask\n",
    "        self.anchors = anchors\n",
    "        self.class_num = class_num\n",
    "\n",
    "        self.yolo_anchors = []\n",
    "        self.yolo_classes = []\n",
    "        for mask_pair in self.anchor_mask:\n",
    "            mask_anchors = []\n",
    "            for mask in mask_pair:\n",
    "                mask_anchors.append(self.anchors[2 * mask])\n",
    "                mask_anchors.append(self.anchors[2 * mask + 1])\n",
    "            self.yolo_anchors.append(mask_anchors)\n",
    "            self.yolo_classes.append(class_num)\n",
    "\n",
    "    def name(self):\n",
    "        return 'YOLOv3-tiny'\n",
    "\n",
    "    def get_anchors(self):\n",
    "        return self.anchors\n",
    "\n",
    "    def get_anchor_mask(self):\n",
    "        return self.anchor_mask\n",
    "\n",
    "    def get_class_num(self):\n",
    "        return self.class_num\n",
    "\n",
    "    def get_downsample_ratio(self):\n",
    "        return self.downsample_ratio\n",
    "\n",
    "    def get_yolo_anchors(self):\n",
    "        return self.yolo_anchors\n",
    "\n",
    "    def get_yolo_classes(self):\n",
    "        return self.yolo_classes\n",
    "\n",
    "    def conv_bn(self,\n",
    "                input,\n",
    "                num_filters,\n",
    "                filter_size,\n",
    "                stride,\n",
    "                padding,\n",
    "                num_groups=1,\n",
    "                use_cudnn=True):\n",
    "        conv = fluid.layers.conv2d(\n",
    "            input=input,\n",
    "            num_filters=num_filters,\n",
    "            filter_size=filter_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            act=None,\n",
    "            groups=num_groups,\n",
    "            use_cudnn=use_cudnn,\n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "            bias_attr=False)\n",
    "\n",
    "        # batch_norm中的参数不需要参与正则化，所以主动使用正则系数为0的正则项屏蔽掉\n",
    "        out = fluid.layers.batch_norm(\n",
    "            input=conv, act='relu', \n",
    "            param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02), regularizer=L2Decay(0.)),\n",
    "            bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "\n",
    "        return out\n",
    "\n",
    "    def depthwise_conv_bn(self, input, filter_size=3, stride=1, padding=1):\n",
    "        num_filters = input.shape[1]\n",
    "        return self.conv_bn(input, \n",
    "                num_filters=num_filters, \n",
    "                filter_size=filter_size, \n",
    "                stride=stride, \n",
    "                padding=padding, \n",
    "                num_groups=num_filters)\n",
    "\n",
    "    def downsample(self, input, pool_size=2, pool_stride=2):\n",
    "        self.downsample_ratio *= 2\n",
    "        return fluid.layers.pool2d(input=input, pool_type='max', pool_size=pool_size,\n",
    "                                    pool_stride=pool_stride)\n",
    "\n",
    "    def basicblock(self, input, num_filters):\n",
    "        conv1 = self.conv_bn(input, num_filters, filter_size=3, stride=1, padding=1)\n",
    "        out = self.downsample(conv1)\n",
    "        return out\n",
    "\n",
    "\n",
    "    def upsample(self, input, scale=2):\n",
    "        # get dynamic upsample output shape\n",
    "        shape_nchw = fluid.layers.shape(input)\n",
    "        shape_hw = fluid.layers.slice(shape_nchw, axes=[0], starts=[2], ends=[4])\n",
    "        shape_hw.stop_gradient = True\n",
    "        in_shape = fluid.layers.cast(shape_hw, dtype='int32')\n",
    "        out_shape = in_shape * scale\n",
    "        out_shape.stop_gradient = True\n",
    "\n",
    "        # reisze by actual_shape\n",
    "        out = fluid.layers.resize_nearest(\n",
    "            input=input,\n",
    "            scale=scale,\n",
    "            actual_shape=out_shape)\n",
    "        return out\n",
    "    \n",
    "    def yolo_detection_block(self, input, num_filters):\n",
    "        route = self.conv_bn(input, num_filters, filter_size=1, stride=1, padding=0)\n",
    "        tip = self.conv_bn(route, num_filters * 2, filter_size=3, stride=1, padding=1)\n",
    "        return route, tip\n",
    "\n",
    "    def net(self, img): \n",
    "        # darknet-tiny\n",
    "        stages = [16, 32, 64, 128, 256, 512]\n",
    "        assert len(self.anchor_mask) <= len(stages), \"anchor masks can't bigger than downsample times\"\n",
    "        # 256x256\n",
    "        tmp = img\n",
    "        blocks = []\n",
    "        for i, stage_count in enumerate(stages):\n",
    "            if i == len(stages) - 1:\n",
    "                block = self.conv_bn(tmp, stage_count, filter_size=3, stride=1, padding=1)\n",
    "                blocks.append(block)\n",
    "                block = self.depthwise_conv_bn(blocks[-1])\n",
    "                block = self.depthwise_conv_bn(blocks[-1])\n",
    "                block = self.conv_bn(blocks[-1], stage_count * 2, filter_size=1, stride=1, padding=0)\n",
    "                blocks.append(block)\n",
    "            else:\n",
    "                tmp = self.basicblock(tmp, stage_count)\n",
    "                blocks.append(tmp)\n",
    "        \n",
    "        blocks = [blocks[-1], blocks[3]]\n",
    "\n",
    "        # yolo detector\n",
    "        for i, block in enumerate(blocks):\n",
    "            # yolo 中跨视域链接\n",
    "            if i > 0:\n",
    "                block = fluid.layers.concat(input=[route, block], axis=1)\n",
    "            if i < 1:\n",
    "                route, tip = self.yolo_detection_block(block, num_filters=256 // (2**i))\n",
    "            else:\n",
    "                tip = self.conv_bn(block, num_filters=256, filter_size=3, stride=1, padding=1)\n",
    "            block_out = fluid.layers.conv2d(\n",
    "                input=tip,\n",
    "                num_filters=len(self.anchor_mask[i]) * (self.class_num + 5),      # 5 elements represent x|y|h|w|score\n",
    "                filter_size=1,\n",
    "                stride=1,\n",
    "                padding=0,\n",
    "                act=None,\n",
    "                param_attr=ParamAttr(initializer=fluid.initializer.Normal(0., 0.02)),\n",
    "                bias_attr=ParamAttr(initializer=fluid.initializer.Constant(0.0), regularizer=L2Decay(0.)))\n",
    "            self.outputs.append(block_out)\n",
    "            # 为了跨视域链接，差值方式提升特征图尺寸\n",
    "            if i < len(blocks) - 1:\n",
    "                route = self.conv_bn(route, 128 // (2**i), filter_size=1, stride=1, padding=0)\n",
    "                route = self.upsample(route)\n",
    "\n",
    "        return self.outputs\n",
    "        \n",
    "\n",
    "def get_yolo(is_tiny, class_num, anchors, anchor_mask):\n",
    "    if is_tiny:\n",
    "        return YOLOv3Tiny(class_num, anchors, anchor_mask)\n",
    "    else:\n",
    "        return YOLOv3(class_num, anchors, anchor_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化参数，初始化日志的便利函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_train_parameters():\n",
    "    \"\"\"\n",
    "    初始化训练参数，主要是初始化图片数量，类别数\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    file_list = os.path.join(train_parameters['data_dir'], train_parameters['file_list'])\n",
    "    label_list = os.path.join(train_parameters['data_dir'], \"label_list\")\n",
    "    index = 0\n",
    "    with codecs.open(label_list, encoding='utf-8') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        for line in lines:\n",
    "            train_parameters['label_dict'][line.strip()] = index\n",
    "            index += 1\n",
    "        train_parameters['class_dim'] = index\n",
    "    with codecs.open(file_list, encoding='utf-8-sig') as flist:\n",
    "        lines = [line.strip() for line in flist]\n",
    "        train_parameters['image_count'] = len(lines)\n",
    "\n",
    "\n",
    "def init_log_config():\n",
    "    \"\"\"\n",
    "    初始化日志相关配置\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    global logger\n",
    "    logger = logging.getLogger()\n",
    "    logger.setLevel(logging.INFO)\n",
    "    log_path = os.path.join(os.getcwd(), 'logs')\n",
    "    if not os.path.exists(log_path):\n",
    "        os.makedirs(log_path)\n",
    "    log_name = os.path.join(log_path, 'train.log')\n",
    "    sh = logging.StreamHandler()\n",
    "    fh = logging.FileHandler(log_name, mode='w')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter(\"%(asctime)s - %(filename)s[line:%(lineno)d] - %(levelname)s: %(message)s\")\n",
    "    fh.setFormatter(formatter)\n",
    "    sh.setFormatter(formatter)\n",
    "    logger.addHandler(sh)\n",
    "    logger.addHandler(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "图像增强处理的系列函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_to_center_relative(box, img_height, img_width):\n",
    "    \"\"\"\n",
    "    Convert COCO annotations box with format [x1, y1, w, h] to \n",
    "    center mode [center_x, center_y, w, h] and divide image width\n",
    "    and height to get relative value in range[0, 1]\n",
    "    \"\"\"\n",
    "    assert len(box) == 4, \"box should be a len(4) list or tuple\"\n",
    "    x, y, w, h = box\n",
    "\n",
    "    x1 = max(x, 0)\n",
    "    x2 = min(x + w - 1, img_width - 1)\n",
    "    y1 = max(y, 0)\n",
    "    y2 = min(y + h - 1, img_height - 1)\n",
    "\n",
    "    x = (x1 + x2) / 2 / img_width\n",
    "    y = (y1 + y2) / 2 / img_height\n",
    "    w = (x2 - x1) / img_width\n",
    "    h = (y2 - y1) / img_height\n",
    "\n",
    "    return np.array([x, y, w, h])\n",
    "\n",
    "\n",
    "def resize_img(img, sampled_labels, input_size):\n",
    "    target_size = input_size\n",
    "    img = img.resize((target_size[1], target_size[2]), Image.BILINEAR)\n",
    "    return img\n",
    "\n",
    "\n",
    "def box_iou_xywh(box1, box2):\n",
    "    assert box1.shape[-1] == 4, \"Box1 shape[-1] should be 4.\"\n",
    "    assert box2.shape[-1] == 4, \"Box2 shape[-1] should be 4.\"\n",
    "\n",
    "    b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
    "    b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
    "    b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
    "    b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
    "\n",
    "    inter_x1 = np.maximum(b1_x1, b2_x1)\n",
    "    inter_x2 = np.minimum(b1_x2, b2_x2)\n",
    "    inter_y1 = np.maximum(b1_y1, b2_y1)\n",
    "    inter_y2 = np.minimum(b1_y2, b2_y2)\n",
    "    inter_w = inter_x2 - inter_x1 + 1\n",
    "    inter_h = inter_y2 - inter_y1 + 1\n",
    "    inter_w[inter_w < 0] = 0\n",
    "    inter_h[inter_h < 0] = 0\n",
    "\n",
    "    inter_area = inter_w * inter_h\n",
    "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
    "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
    "\n",
    "    return inter_area / (b1_area + b2_area - inter_area)\n",
    "\n",
    "\n",
    "def box_crop(boxes, labels, crop, img_shape):\n",
    "    x, y, w, h = map(float, crop)\n",
    "    im_w, im_h = map(float, img_shape)\n",
    "\n",
    "    boxes = boxes.copy()\n",
    "    boxes[:, 0], boxes[:, 2] = (boxes[:, 0] - boxes[:, 2] / 2) * im_w, (boxes[:, 0] + boxes[:, 2] / 2) * im_w\n",
    "    boxes[:, 1], boxes[:, 3] = (boxes[:, 1] - boxes[:, 3] / 2) * im_h, (boxes[:, 1] + boxes[:, 3] / 2) * im_h\n",
    "\n",
    "    crop_box = np.array([x, y, x + w, y + h])\n",
    "    centers = (boxes[:, :2] + boxes[:, 2:]) / 2.0\n",
    "    mask = np.logical_and(crop_box[:2] <= centers, centers <= crop_box[2:]).all(axis=1)\n",
    "\n",
    "    boxes[:, :2] = np.maximum(boxes[:, :2], crop_box[:2])\n",
    "    boxes[:, 2:] = np.minimum(boxes[:, 2:], crop_box[2:])\n",
    "    boxes[:, :2] -= crop_box[:2]\n",
    "    boxes[:, 2:] -= crop_box[:2]\n",
    "\n",
    "    mask = np.logical_and(mask, (boxes[:, :2] < boxes[:, 2:]).all(axis=1))\n",
    "    boxes = boxes * np.expand_dims(mask.astype('float32'), axis=1)\n",
    "    labels = labels * mask.astype('float32')\n",
    "    boxes[:, 0], boxes[:, 2] = (boxes[:, 0] + boxes[:, 2]) / 2 / w, (boxes[:, 2] - boxes[:, 0]) / w\n",
    "    boxes[:, 1], boxes[:, 3] = (boxes[:, 1] + boxes[:, 3]) / 2 / h, (boxes[:, 3] - boxes[:, 1]) / h\n",
    "\n",
    "    return boxes, labels, mask.sum()\n",
    "\n",
    "\n",
    "def random_brightness(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_distort_strategy']['brightness_prob']:\n",
    "        brightness_delta = train_parameters['image_distort_strategy']['brightness_delta']\n",
    "        delta = np.random.uniform(-brightness_delta, brightness_delta) + 1\n",
    "        img = ImageEnhance.Brightness(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_contrast(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_distort_strategy']['contrast_prob']:\n",
    "        contrast_delta = train_parameters['image_distort_strategy']['contrast_delta']\n",
    "        delta = np.random.uniform(-contrast_delta, contrast_delta) + 1\n",
    "        img = ImageEnhance.Contrast(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_saturation(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_distort_strategy']['saturation_prob']:\n",
    "        saturation_delta = train_parameters['image_distort_strategy']['saturation_delta']\n",
    "        delta = np.random.uniform(-saturation_delta, saturation_delta) + 1\n",
    "        img = ImageEnhance.Color(img).enhance(delta)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_hue(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    if prob < train_parameters['image_distort_strategy']['hue_prob']:\n",
    "        hue_delta = train_parameters['image_distort_strategy']['hue_delta']\n",
    "        delta = np.random.uniform(-hue_delta, hue_delta)\n",
    "        img_hsv = np.array(img.convert('HSV'))\n",
    "        img_hsv[:, :, 0] = img_hsv[:, :, 0] + delta\n",
    "        img = Image.fromarray(img_hsv, mode='HSV').convert('RGB')\n",
    "    return img\n",
    "\n",
    "\n",
    "def distort_image(img):\n",
    "    prob = np.random.uniform(0, 1)\n",
    "    # Apply different distort order\n",
    "    if prob > 0.5:\n",
    "        img = random_brightness(img)\n",
    "        img = random_contrast(img)\n",
    "        img = random_saturation(img)\n",
    "        img = random_hue(img)\n",
    "    else:\n",
    "        img = random_brightness(img)\n",
    "        img = random_saturation(img)\n",
    "        img = random_hue(img)\n",
    "        img = random_contrast(img)\n",
    "    return img\n",
    "\n",
    "\n",
    "def random_crop(img, boxes, labels, scales=[0.3, 1.0], max_ratio=2.0, constraints=None, max_trial=50):\n",
    "    if random.random() > 0.6:\n",
    "        return img, boxes, labels\n",
    "    if len(boxes) == 0:\n",
    "        return img, boxes, labels\n",
    "\n",
    "    if not constraints:\n",
    "        constraints = [\n",
    "                (0.1, 1.0),\n",
    "                (0.3, 1.0),\n",
    "                (0.5, 1.0),\n",
    "                (0.7, 1.0),\n",
    "                (0.9, 1.0),\n",
    "                (0.0, 1.0)]\n",
    "\n",
    "    w, h = img.size\n",
    "    crops = [(0, 0, w, h)]\n",
    "    for min_iou, max_iou in constraints:\n",
    "        for _ in range(max_trial):\n",
    "            scale = random.uniform(scales[0], scales[1])\n",
    "            aspect_ratio = random.uniform(max(1 / max_ratio, scale * scale), \\\n",
    "                                          min(max_ratio, 1 / scale / scale))\n",
    "            crop_h = int(h * scale / np.sqrt(aspect_ratio))\n",
    "            crop_w = int(w * scale * np.sqrt(aspect_ratio))\n",
    "            crop_x = random.randrange(w - crop_w)\n",
    "            crop_y = random.randrange(h - crop_h)\n",
    "            crop_box = np.array([[\n",
    "                (crop_x + crop_w / 2.0) / w,\n",
    "                (crop_y + crop_h / 2.0) / h,\n",
    "                crop_w / float(w),\n",
    "                crop_h /float(h)\n",
    "                ]])\n",
    "\n",
    "            iou = box_iou_xywh(crop_box, boxes)\n",
    "            if min_iou <= iou.min() and max_iou >= iou.max():\n",
    "                crops.append((crop_x, crop_y, crop_w, crop_h))\n",
    "                break\n",
    "\n",
    "    while crops:\n",
    "        crop = crops.pop(np.random.randint(0, len(crops)))\n",
    "        crop_boxes, crop_labels, box_num = box_crop(boxes, labels, crop, (w, h))\n",
    "        if box_num < 1:\n",
    "            continue\n",
    "        img = img.crop((crop[0], crop[1], crop[0] + crop[2], \n",
    "                        crop[1] + crop[3])).resize(img.size, Image.LANCZOS)\n",
    "        return img, crop_boxes, crop_labels\n",
    "    return img, boxes, labels\n",
    "\n",
    "\n",
    "def random_expand(img, gtboxes, keep_ratio=True):\n",
    "    if np.random.uniform(0, 1) < train_parameters['image_distort_strategy']['expand_prob']:\n",
    "        return img, gtboxes\n",
    "\n",
    "    max_ratio = train_parameters['image_distort_strategy']['expand_max_ratio']    \n",
    "    w, h = img.size\n",
    "    c = 3\n",
    "    ratio_x = random.uniform(1, max_ratio)\n",
    "    if keep_ratio:\n",
    "        ratio_y = ratio_x\n",
    "    else:\n",
    "        ratio_y = random.uniform(1, max_ratio)\n",
    "    oh = int(h * ratio_y)\n",
    "    ow = int(w * ratio_x)\n",
    "    off_x = random.randint(0, ow -w)\n",
    "    off_y = random.randint(0, oh -h)\n",
    "\n",
    "    out_img = np.zeros((oh, ow, c), np.uint8)\n",
    "    for i in range(c):\n",
    "        out_img[:, :, i] = train_parameters['mean_rgb'][i]\n",
    "\n",
    "    out_img[off_y: off_y + h, off_x: off_x + w, :] = img\n",
    "    gtboxes[:, 0] = ((gtboxes[:, 0] * w) + off_x) / float(ow)\n",
    "    gtboxes[:, 1] = ((gtboxes[:, 1] * h) + off_y) / float(oh)\n",
    "    gtboxes[:, 2] = gtboxes[:, 2] / ratio_x\n",
    "    gtboxes[:, 3] = gtboxes[:, 3] / ratio_y\n",
    "\n",
    "    return Image.fromarray(out_img), gtboxes\n",
    "\n",
    "\n",
    "def preprocess(img, bbox_labels, input_size, mode):\n",
    "    img_width, img_height = img.size\n",
    "    sample_labels = np.array(bbox_labels)\n",
    "    if mode == 'train':\n",
    "        if train_parameters['apply_distort']:\n",
    "            img = distort_image(img)\n",
    "        img, gtboxes = random_expand(img, sample_labels[:, 1:5])\n",
    "        img, gtboxes, gtlabels = random_crop(img, gtboxes, sample_labels[:, 0])\n",
    "        sample_labels[:, 0] = gtlabels\n",
    "        sample_labels[:, 1:5] = gtboxes\n",
    "    img = resize_img(img, sample_labels, input_size)\n",
    "    img = np.array(img).astype('float32')\n",
    "    img -= train_parameters['mean_rgb']\n",
    "    img = img.transpose((2, 0, 1))  # HWC to CHW\n",
    "    img *= 0.007843\n",
    "    return img, sample_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "自定义数据读取器，如果需要自定义数据，需要修改下面这段函数，以适配自定义数据的格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_reader(file_list, data_dir, input_size, mode):\n",
    "    def reader():\n",
    "        np.random.shuffle(file_list)\n",
    "        for line in file_list:\n",
    "            if mode == 'train' or mode == 'eval':\n",
    "                ######################  以下可能是需要自定义修改的部分   ############################\n",
    "                parts = line.split()\n",
    "                image_path = parts[0]\n",
    "                img = Image.open(image_path)\n",
    "                if img.mode != 'RGB':\n",
    "                    img = img.convert('RGB')\n",
    "                im_width, im_height = img.size\n",
    "                # bbox 的列表，每一个元素为这样\n",
    "                # layout: label | x-center | y-cneter | width | height | difficult\n",
    "                bbox_labels = []\n",
    "                for object_str in parts[1:]:\n",
    "                    bbox_sample = []\n",
    "                    object = json.loads(object_str)\n",
    "                    bbox_sample.append(float(train_parameters['label_dict'][object['value']]))\n",
    "                    bbox = object['coordinate']\n",
    "                    box = [bbox[0][0], bbox[0][1], bbox[1][0] - bbox[0][0], bbox[1][1] - bbox[0][1]]\n",
    "                    bbox = box_to_center_relative(box, im_height, im_width)\n",
    "                    bbox_sample.append(float(bbox[0]))\n",
    "                    bbox_sample.append(float(bbox[1]))\n",
    "                    bbox_sample.append(float(bbox[2]))\n",
    "                    bbox_sample.append(float(bbox[3]))\n",
    "                    difficult = float(0)\n",
    "                    bbox_sample.append(difficult)\n",
    "                    bbox_labels.append(bbox_sample)\n",
    "                ######################  可能需要自定义修改部分结束   ############################\n",
    "                if len(bbox_labels) == 0: continue\n",
    "                img, sample_labels = preprocess(img, bbox_labels, input_size, mode)\n",
    "                # sample_labels = np.array(sample_labels)\n",
    "                if len(sample_labels) == 0: continue\n",
    "                boxes = sample_labels[:, 1:5]\n",
    "                lbls = sample_labels[:, 0].astype('int32')\n",
    "                difficults = sample_labels[:, -1].astype('int32')\n",
    "                max_box_num = train_parameters['max_box_num']\n",
    "                cope_size = max_box_num if len(boxes) >= max_box_num else len(boxes)\n",
    "                ret_boxes = np.zeros((max_box_num, 4), dtype=np.float32)\n",
    "                ret_lbls = np.zeros((max_box_num), dtype=np.int32)\n",
    "                ret_difficults = np.zeros((max_box_num), dtype=np.int32)\n",
    "                ret_boxes[0: cope_size] = boxes[0: cope_size]\n",
    "                ret_lbls[0: cope_size] = lbls[0: cope_size]\n",
    "                ret_difficults[0: cope_size] = difficults[0: cope_size]\n",
    "                yield img, ret_boxes, ret_lbls, ret_difficults\n",
    "            elif mode == 'test':\n",
    "                img_path = os.path.join(line)\n",
    "                yield Image.open(img_path)\n",
    "\n",
    "    return reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "定义异步数据读取\n",
    "\n",
    "定义优化器\n",
    "\n",
    "构建 program 和损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_process_custom_reader(file_path, data_dir, num_workers, input_size, mode):\n",
    "    file_path = os.path.join(data_dir, file_path)\n",
    "    readers = []\n",
    "    images = [line.strip() for line in open(file_path)]\n",
    "    n = int(math.ceil(len(images) // num_workers))\n",
    "    image_lists = [images[i: i + n] for i in range(0, len(images), n)]\n",
    "    for l in image_lists:\n",
    "        readers.append(paddle.batch(custom_reader(l, data_dir, input_size, mode), \n",
    "                                    batch_size=train_parameters['train_batch_size']))\n",
    "    return paddle.reader.multiprocess_reader(readers, False)\n",
    "\n",
    "\n",
    "def create_eval_reader(file_path, data_dir, input_size, mode):\n",
    "    file_path = os.path.join(data_dir, file_path)\n",
    "    images = [line.strip() for line in open(file_path)]\n",
    "    return paddle.batch(custom_reader(images, data_dir, input_size, mode), \n",
    "                        batch_size=train_parameters['train_batch_size'],\n",
    "                        drop_last=True)\n",
    "\n",
    "\n",
    "def optimizer_momentum_setting():\n",
    "    learning_strategy = train_parameters['momentum_strategy']\n",
    "    learning_rate = fluid.layers.exponential_decay(learning_rate=learning_strategy['learning_rate'],\n",
    "                                                   decay_steps=learning_strategy['decay_steps'],\n",
    "                                                   decay_rate=learning_strategy['decay_rate'])\n",
    "    optimizer = fluid.optimizer.MomentumOptimizer(learning_rate=learning_rate, momentum=0.1)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def optimizer_rms_setting():\n",
    "    batch_size = train_parameters[\"train_batch_size\"]\n",
    "    iters = train_parameters[\"image_count\"] // batch_size\n",
    "    learning_strategy = train_parameters['rsm_strategy']\n",
    "    lr = learning_strategy['learning_rate']\n",
    "\n",
    "    boundaries = [i * iters for i in learning_strategy[\"lr_epochs\"]]\n",
    "    values = [i * lr for i in learning_strategy[\"lr_decay\"]]\n",
    "\n",
    "    optimizer = fluid.optimizer.RMSProp(\n",
    "        learning_rate=fluid.layers.piecewise_decay(boundaries, values),\n",
    "        regularization=fluid.regularizer.L2Decay(0.00005))\n",
    "\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def build_train_program_with_async_reader(main_prog, startup_prog):\n",
    "    max_box_num = train_parameters['max_box_num']\n",
    "    ues_tiny = train_parameters['use_tiny']\n",
    "    yolo_config = train_parameters['yolo_tiny_cfg'] if ues_tiny else train_parameters['yolo_cfg']\n",
    "    with fluid.program_guard(main_prog, startup_prog):\n",
    "        img = fluid.layers.data(name='img', shape=yolo_config['input_size'], dtype='float32')\n",
    "        gt_box = fluid.layers.data(name='gt_box', shape=[max_box_num, 4], dtype='float32', lod_level=0)\n",
    "        gt_label = fluid.layers.data(name='gt_label', shape=[max_box_num], dtype='int32', lod_level=0)\n",
    "        difficult = fluid.layers.data(name='difficult', shape=[max_box_num], dtype='int32', lod_level=0)\n",
    "        data_reader = fluid.layers.create_py_reader_by_data(capacity=train_parameters['train_batch_size'],\n",
    "                                                            feed_list=[img, gt_box, gt_label, difficult],\n",
    "                                                            name='train')\n",
    "        multi_reader = multi_process_custom_reader(train_parameters['file_list'],\n",
    "                                                   train_parameters['data_dir'],\n",
    "                                                   train_parameters['multi_data_reader_count'],\n",
    "                                                   yolo_config['input_size'],\n",
    "                                                   'train')\n",
    "        data_reader.decorate_paddle_reader(multi_reader)\n",
    "        with fluid.unique_name.guard():\n",
    "            img, gt_box, gt_label, difficult = fluid.layers.read_file(data_reader)\n",
    "            model = get_yolo(ues_tiny, train_parameters['class_dim'], yolo_config['anchors'], yolo_config['anchor_mask'])\n",
    "            outputs = model.net(img)\n",
    "            losses = []\n",
    "            downsample_ratio = model.get_downsample_ratio()\n",
    "            with fluid.unique_name.guard('train'):\n",
    "                for i, out in enumerate(outputs):\n",
    "                    logger.info(\"{0} downsample_ratio: {1} output:{2}\".format(i, downsample_ratio, out))\n",
    "                    loss = fluid.layers.yolov3_loss(\n",
    "                            x=out,\n",
    "                            gtbox=gt_box,\n",
    "                            gtlabel=gt_label,\n",
    "                            anchors=model.get_anchors(),\n",
    "                            anchor_mask=model.get_anchor_mask()[i],\n",
    "                            class_num=model.get_class_num(),\n",
    "                            ignore_thresh=train_parameters['ignore_thresh'],\n",
    "                            downsample_ratio=downsample_ratio)\n",
    "                    losses.append(fluid.layers.reduce_mean(loss))\n",
    "                    downsample_ratio //= 2\n",
    "                loss = sum(losses)\n",
    "                optimizer = optimizer_rms_setting()\n",
    "                optimizer.minimize(loss)\n",
    "                return data_reader, loss\n",
    "\n",
    "\n",
    "def build_eval_program_with_feeder(main_prog, startup_prog, place):\n",
    "    ues_tiny = train_parameters['use_tiny']\n",
    "    yolo_config = train_parameters['yolo_tiny_cfg'] if ues_tiny else train_parameters['yolo_cfg']\n",
    "    with fluid.program_guard(main_prog, startup_prog):\n",
    "        img = fluid.layers.data(name='img', shape=yolo_config['input_size'], dtype='float32')\n",
    "        gt_box = fluid.layers.data(name='gt_box', shape=[4], dtype='float32', lod_level=1)\n",
    "        gt_label = fluid.layers.data(name='gt_label', shape=[1], dtype='int32', lod_level=1)\n",
    "        difficult = fluid.layers.data(name='difficult', shape=[1], dtype='int32', lod_level=1)\n",
    "        feeder = fluid.DataFeeder(feed_list=[img, gt_box, gt_label, difficult], place=place, program=main_prog)\n",
    "        reader = create_eval_reader(train_parameters['file_list'], train_parameters['data_dir'], \n",
    "                                    yolo_config['input_size'], 'eval')\n",
    "        with fluid.unique_name.guard():\n",
    "            model = get_yolo(ues_tiny, train_parameters['class_dim'], yolo_config['anchors'], yolo_config['anchor_mask'])\n",
    "            outputs = model.net(img)\n",
    "            return feeder, reader, outputs, gt_box, gt_label, difficult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载已经有的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pretrained_params(exe, program):\n",
    "    if train_parameters['continue_train'] and os.path.exists(train_parameters['save_model_dir']):\n",
    "        logger.info('load param from retrain model')\n",
    "        fluid.io.load_persistables(executor=exe,\n",
    "                                   dirname=train_parameters['save_model_dir'],\n",
    "                                   main_program=program)\n",
    "    elif train_parameters['pretrained'] and os.path.exists(train_parameters['pretrained_model_dir']):\n",
    "        logger.info('load param from pretrained model')\n",
    "        def if_exist(var):\n",
    "            return os.path.exists(os.path.join(train_parameters['pretrained_model_dir'], var.name))\n",
    "\n",
    "        fluid.io.load_vars(exe, train_parameters['pretrained_model_dir'], main_program=program,\n",
    "                           predicate=if_exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练主体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    init_log_config()\n",
    "    init_train_parameters()\n",
    "    logger.info(\"start train YOLOv3, train params:%s\", str(train_parameters))\n",
    "\n",
    "    logger.info(\"create place, use gpu:\" + str(train_parameters['use_gpu']))\n",
    "    place = fluid.CUDAPlace(0) if train_parameters['use_gpu'] else fluid.CPUPlace()\n",
    "\n",
    "    logger.info(\"build network and program\")\n",
    "    train_program = fluid.Program()\n",
    "    start_program = fluid.Program()\n",
    "    eval_program = fluid.Program()\n",
    "    start_program = fluid.Program()\n",
    "    train_reader, loss = build_train_program_with_async_reader(train_program, start_program)\n",
    "    eval_feeder, eval_reader, outputs, gt_box, gt_label, difficult = build_eval_program_with_feeder(eval_program, start_program, place)\n",
    "    eval_program = eval_program.clone(for_test=True)\n",
    "\n",
    "    logger.info(\"build executor and init params\")\n",
    "    exe = fluid.Executor(place)\n",
    "    exe.run(start_program)\n",
    "    train_fetch_list = [loss.name]\n",
    "    eval_fetch_list = [v.name for v in outputs]\n",
    "    load_pretrained_params(exe, train_program)\n",
    "\n",
    "\n",
    "    stop_strategy = train_parameters['early_stop']\n",
    "    successive_limit = stop_strategy['successive_limit']\n",
    "    sample_freq = stop_strategy['sample_frequency']\n",
    "    min_curr_map = stop_strategy['min_curr_map']\n",
    "    min_loss = stop_strategy['min_loss']\n",
    "    stop_train = False\n",
    "    successive_count = 0\n",
    "    total_batch_count = 0\n",
    "    valid_thresh = train_parameters['valid_thresh']\n",
    "    nms_thresh = train_parameters['nms_thresh']\n",
    "    for pass_id in range(train_parameters[\"num_epochs\"]):\n",
    "        logger.info(\"current pass: %d, start read image\", pass_id)\n",
    "        batch_id = 0\n",
    "        train_reader.start()\n",
    "        try:\n",
    "            while True:\n",
    "                t1 = time.time()\n",
    "                loss = exe.run(train_program, fetch_list=train_fetch_list)\n",
    "                period = time.time() - t1\n",
    "                loss = np.mean(np.array(loss))\n",
    "                batch_id += 1\n",
    "                total_batch_count += 1\n",
    "\n",
    "                if batch_id % 10 == 0:\n",
    "                    logger.info(\n",
    "                        \"Pass {0}, trainbatch {1}, loss {2} time {3}\".format(pass_id, batch_id, loss, \"%2.2f sec\" % period))\n",
    "                # 采用简单的定时采样停止办法，可以调整为更精细的保存策略\n",
    "                if total_batch_count % 100 == 0:\n",
    "                    logger.info(\"temp save {0} batch train result\".format(total_batch_count))\n",
    "                    fluid.io.save_persistables(dirname=train_parameters['save_model_dir'],\n",
    "                                               main_program=train_program,\n",
    "                                               executor=exe)\n",
    "        except fluid.core.EOFException:\n",
    "            train_reader.reset()\n",
    "\n",
    "    logger.info(\"training till last epcho, end training\")\n",
    "    fluid.io.save_persistables(dirname=train_parameters['save_model_dir'], main_program=train_program, executor=exe)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -cf yolo-model.tar yolo-model/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将模型固化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {}\n",
    "with codecs.open('data/data6045/label_list.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        label_dict[float(parts[0])] = parts[1]\n",
    "print(label_dict)\n",
    "class_dim = len(label_dict)\n",
    "\n",
    "def freeze_model():\n",
    "\n",
    "    path = \"./yolo-model\"\n",
    "    exe = fluid.Executor(fluid.CPUPlace())\n",
    "\n",
    "    ues_tiny = train_parameters['use_tiny']\n",
    "    yolo_config = train_parameters['yolo_tiny_cfg'] if ues_tiny else train_parameters['yolo_cfg']\n",
    "    model = model = get_yolo(ues_tiny, class_dim, yolo_config['anchors'], yolo_config['anchor_mask'])\n",
    "    image = fluid.layers.data(name='image', shape=yolo_config['input_size'], dtype='float32')\n",
    "    pred = model.net(image)\n",
    "    \n",
    "    freeze_program = fluid.default_main_program()\n",
    "    fluid.io.load_persistables(exe, path, freeze_program)\n",
    "    freeze_program = freeze_program.clone(for_test=True)\n",
    "\n",
    "    fluid.io.save_inference_model(\"./freeze_model\", ['image'], pred, exe, freeze_program)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    freeze_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用固化的模型进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "from PIL import Image\n",
    "from PIL import ImageFont\n",
    "from PIL import ImageDraw\n",
    "\n",
    "\n",
    "ues_tiny = train_parameters['use_tiny']\n",
    "yolo_config = train_parameters['yolo_tiny_cfg'] if ues_tiny else train_parameters['yolo_cfg']\n",
    "\n",
    "target_size = yolo_config['input_size']\n",
    "anchors = yolo_config['anchors']\n",
    "anchor_mask = yolo_config['anchor_mask']\n",
    "\n",
    "nms_threshold = 0.4\n",
    "valid_thresh = 0.4\n",
    "confs_threshold = 0.5\n",
    "label_dict = {}\n",
    "with codecs.open('data/data6045/label_list.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        label_dict[str(float(parts[0]))] = parts[1]\n",
    "print(label_dict)\n",
    "class_dim = len(label_dict)\n",
    "\n",
    "place = fluid.CPUPlace()\n",
    "exe = fluid.Executor(place)\n",
    "path = \"./freeze_model\"\n",
    "[inference_program, feed_target_names, fetch_targets] = fluid.io.load_inference_model(dirname=path, executor=exe)\n",
    "\n",
    "\n",
    "def get_yolo_anchors_classes(class_num, anchors, anchor_mask):\n",
    "    yolo_anchors = []\n",
    "    yolo_classes = []\n",
    "    for mask_pair in anchor_mask:\n",
    "        mask_anchors = []\n",
    "        for mask in mask_pair:\n",
    "            mask_anchors.append(anchors[2 * mask])\n",
    "            mask_anchors.append(anchors[2 * mask + 1])\n",
    "        yolo_anchors.append(mask_anchors)\n",
    "        yolo_classes.append(class_num)\n",
    "    return yolo_anchors, yolo_classes\n",
    "\n",
    "\n",
    "def draw_bbox_image(img, boxes, labels, save_name):\n",
    "    \"\"\"\n",
    "    给图片画上外接矩形框\n",
    "    :param img:\n",
    "    :param boxes:\n",
    "    :param save_name:\n",
    "    :param labels\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # font = ImageFont.truetype(\"font.ttf\", 25)\n",
    "    img_width, img_height = img.size\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    for box, label in zip(boxes, labels):\n",
    "        xmin, ymin, xmax, ymax = box[0], box[1], box[2], box[3]\n",
    "        draw.rectangle((xmin, ymin, xmax, ymax), None, 'red')\n",
    "        draw.text((xmin, ymin), label_dict[str(label)], (255, 255, 0))\n",
    "    img.save(save_name)\n",
    "\n",
    "\n",
    "def clip_bbox(bbox):\n",
    "    \"\"\"\n",
    "    截断矩形框\n",
    "    :param bbox:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    xmin = max(min(bbox[0], 1.), 0.)\n",
    "    ymin = max(min(bbox[1], 1.), 0.)\n",
    "    xmax = max(min(bbox[2], 1.), 0.)\n",
    "    ymax = max(min(bbox[3], 1.), 0.)\n",
    "    return xmin, ymin, xmax, ymax\n",
    "\n",
    "\n",
    "def resize_img(img, target_size):\n",
    "    \"\"\"\n",
    "    保持比例的缩放图片\n",
    "    :param img:\n",
    "    :param target_size:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    img = img.resize(target_size[1:], Image.ANTIALIAS)\n",
    "    return img\n",
    "\n",
    "\n",
    "def read_image(img_path):\n",
    "    \"\"\"\n",
    "    读取图片\n",
    "    :param img_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    origin = Image.open(img_path)\n",
    "    img = resize_img(origin, target_size)\n",
    "    resized_img = img.copy()\n",
    "    if img.mode != 'RGB':\n",
    "        img = img.convert('RGB')\n",
    "    img = np.array(img).astype('float32').transpose((2, 0, 1))  # HWC to CHW\n",
    "    img -= 127.5\n",
    "    img *= 0.007843\n",
    "    img = img[np.newaxis, :]\n",
    "    return origin, img, resized_img\n",
    "\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Perform sigmoid to input numpy array\"\"\"\n",
    "    return 1.0 / (1.0 + np.exp(-1.0 * x))\n",
    "\n",
    "\n",
    "def box_xywh_to_xyxy(box):\n",
    "    \"\"\"\n",
    "    bbox 两种形式的转换，左上角和宽高---->左上角|右下角\n",
    "    :param box:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    shape = box.shape\n",
    "    assert shape[-1] == 4, \"Box shape[-1] should be 4.\"\n",
    "\n",
    "    box = box.reshape((-1, 4))\n",
    "    box[:, 0], box[:, 2] = box[:, 0] - box[:, 2] / 2, box[:, 0] + box[:, 2] / 2\n",
    "    box[:, 1], box[:, 3] = box[:, 1] - box[:, 3] / 2, box[:, 1] + box[:, 3] / 2\n",
    "    box = box.reshape(shape)\n",
    "    return box\n",
    "\n",
    "\n",
    "def box_iou_xyxy(box1, box2):\n",
    "    assert box1.shape[-1] == 4, \"Box1 shape[-1] should be 4.\"\n",
    "    assert box2.shape[-1] == 4, \"Box2 shape[-1] should be 4.\"\n",
    "\n",
    "    b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
    "    b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
    "\n",
    "    inter_x1 = np.maximum(b1_x1, b2_x1)\n",
    "    inter_x2 = np.minimum(b1_x2, b2_x2)\n",
    "    inter_y1 = np.maximum(b1_y1, b2_y1)\n",
    "    inter_y2 = np.minimum(b1_y2, b2_y2)\n",
    "    inter_w = inter_x2 - inter_x1\n",
    "    inter_h = inter_y2 - inter_y1\n",
    "    inter_w[inter_w < 0] = 0\n",
    "    inter_h[inter_h < 0] = 0\n",
    "\n",
    "    inter_area = inter_w * inter_h\n",
    "    b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
    "    b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
    "    \n",
    "    return inter_area / (b1_area + b2_area - inter_area)\n",
    "\n",
    "\n",
    "def rescale_box_in_input_image(boxes, im_shape, input_size):\n",
    "    \"\"\"Scale (x1, x2, y1, y2) box of yolo output to input image\"\"\"\n",
    "    h, w = im_shape\n",
    "    fx = w / input_size\n",
    "    fy = h / input_size\n",
    "    boxes[:, 0] *= fx\n",
    "    boxes[:, 1] *= fy\n",
    "    boxes[:, 2] *= fx\n",
    "    boxes[:, 3] *= fy\n",
    "    boxes[boxes<0] = 0\n",
    "    boxes[:, 2][boxes[:, 2] > (w - 1)] = w - 1\n",
    "    boxes[:, 3][boxes[:, 3] > (h - 1)] = h - 1\n",
    "    return boxes\n",
    "\n",
    "\n",
    "def get_yolo_detection(preds, anchors, class_num, img_height, img_width):\n",
    "    \"\"\"Get yolo box, confidence score, class label from Darknet53 output\"\"\"\n",
    "    preds_n = np.array(preds)\n",
    "    n, c, h, w = preds_n.shape\n",
    "    print(preds_n.shape, anchors)\n",
    "    anchor_num = len(anchors) // 2\n",
    "    preds_n = preds_n.reshape([n, anchor_num, class_num + 5, h, w]).transpose((0, 1, 3, 4, 2))\n",
    "    preds_n[:, :, :, :, :2] = sigmoid(preds_n[:, :, :, :, :2])\n",
    "    preds_n[:, :, :, :, 4:] = sigmoid(preds_n[:, :, :, :, 4:])\n",
    "\n",
    "    pred_boxes = preds_n[:, :, :, :, :4]\n",
    "    pred_confs = preds_n[:, :, :, :, 4]\n",
    "    pred_scores = preds_n[:, :, :, :, 5:] * np.expand_dims(pred_confs, axis=4)\n",
    "\n",
    "    grid_x = np.tile(np.arange(w).reshape((1, w)), (h, 1))\n",
    "    grid_y = np.tile(np.arange(h).reshape((h, 1)), (1, w))\n",
    "    anchors = [(anchors[i], anchors[i+1]) for i in range(0, len(anchors), 2)]\n",
    "    anchors_s = np.array([(an_w, an_h) for an_w, an_h in anchors])\n",
    "    anchor_w = anchors_s[:, 0:1].reshape((1, anchor_num, 1, 1))\n",
    "    anchor_h = anchors_s[:, 1:2].reshape((1, anchor_num, 1, 1))\n",
    "\n",
    "    pred_boxes[:, :, :, :, 0] += grid_x\n",
    "    pred_boxes[:, :, :, :, 1] += grid_y\n",
    "    pred_boxes[:, :, :, :, 2] = np.exp(pred_boxes[:, :, :, :, 2]) * anchor_w\n",
    "    pred_boxes[:, :, :, :, 3] = np.exp(pred_boxes[:, :, :, :, 3]) * anchor_h\n",
    "    \n",
    "    pred_boxes[:, :, :, :, 0] = pred_boxes[:, :, :, :, 0] * img_width / w\n",
    "    pred_boxes[:, :, :, :, 1] = pred_boxes[:, :, :, :, 1] * img_height / h\n",
    "    pred_boxes[:, :, :, :, 2] = pred_boxes[:, :, :, :, 2]\n",
    "    pred_boxes[:, :, :, :, 3] = pred_boxes[:, :, :, :, 3]\n",
    "\n",
    "    pred_boxes = box_xywh_to_xyxy(pred_boxes)\n",
    "    pred_boxes = np.tile(np.expand_dims(pred_boxes, axis=4), (1, 1, 1, 1, class_num, 1))\n",
    "    pred_labels = np.zeros_like(pred_scores) + np.arange(class_num)\n",
    "\n",
    "    return pred_boxes.reshape((n, -1, 4)), pred_scores.reshape((n, -1)), pred_labels.reshape((n, -1))\n",
    "\n",
    "\n",
    "def get_all_yolo_pred(outputs, yolo_anchors, yolo_classes, input_shape):\n",
    "    all_pred_boxes = []\n",
    "    all_pred_scores = []\n",
    "    all_pred_labels = []\n",
    "    for output, anchors, classes in zip(outputs, yolo_anchors, yolo_classes):\n",
    "        pred_boxes, pred_scores, pred_labels = get_yolo_detection(output, anchors, classes, input_shape[0], input_shape[1])\n",
    "        all_pred_boxes.append(pred_boxes)\n",
    "        all_pred_labels.append(pred_labels)\n",
    "        all_pred_scores.append(pred_scores)\n",
    "    pred_boxes = np.concatenate(all_pred_boxes, axis=1)\n",
    "    pred_scores = np.concatenate(all_pred_scores, axis=1)\n",
    "    pred_labels = np.concatenate(all_pred_labels, axis=1)\n",
    "\n",
    "    return pred_boxes, pred_scores, pred_labels\n",
    "\n",
    "\n",
    "def calc_nms_box(pred_boxes, pred_scores, pred_labels, valid_thresh=0.4, nms_thresh=0.45, nms_topk=400):\n",
    "    output_boxes = np.empty((0, 4))\n",
    "    output_scores = np.empty(0)\n",
    "    output_labels = np.empty(0)\n",
    "    for boxes, labels, scores in zip(pred_boxes, pred_labels, pred_scores):\n",
    "        valid_mask = scores > valid_thresh\n",
    "        boxes = boxes[valid_mask]\n",
    "        scores = scores[valid_mask]\n",
    "        labels = labels[valid_mask]\n",
    "\n",
    "        score_sort_index = np.argsort(scores)[::-1]\n",
    "        boxes = boxes[score_sort_index][:nms_topk]\n",
    "        scores = scores[score_sort_index][:nms_topk]\n",
    "        labels = labels[score_sort_index][:nms_topk]\n",
    "\n",
    "        for c in np.unique(labels):\n",
    "            c_mask = labels == c\n",
    "            c_boxes = boxes[c_mask]\n",
    "            c_scores = scores[c_mask]\n",
    "\n",
    "            detect_boxes = []\n",
    "            detect_scores = []\n",
    "            detect_labels = []\n",
    "            while c_boxes.shape[0]:\n",
    "                detect_boxes.append(c_boxes[0])\n",
    "                detect_scores.append(c_scores[0])\n",
    "                detect_labels.append(c)\n",
    "                if c_boxes.shape[0] == 1:\n",
    "                    break\n",
    "                iou = box_iou_xyxy(detect_boxes[-1].reshape((1, 4)), c_boxes[1:])\n",
    "                c_boxes = c_boxes[1:][iou < nms_thresh]\n",
    "                c_scores = c_scores[1:][iou < nms_thresh]\n",
    "\n",
    "            output_boxes = np.append(output_boxes, detect_boxes, axis=0)\n",
    "            output_scores = np.append(output_scores, detect_scores)\n",
    "            output_labels = np.append(output_labels, detect_labels)\n",
    "    return output_boxes, output_scores, output_labels\n",
    "\n",
    "\n",
    "def infer(image_path):\n",
    "    \"\"\"\n",
    "    预测，将结果保存到一副新的图片中\n",
    "    :param image_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    origin, tensor_img, resized_img = read_image(image_path)\n",
    "    t1 = time.time()\n",
    "    batch_outputs = exe.run(inference_program,\n",
    "                        feed={feed_target_names[0]: tensor_img},\n",
    "                        fetch_list=fetch_targets)\n",
    "    period = time.time() - t1\n",
    "    print(\"predict cost time:{0}\".format(\"%2.2f sec\" % period))\n",
    "    input_w, input_h = origin.size[0], origin.size[1]\n",
    "    yolo_anchors, yolo_classes = get_yolo_anchors_classes(class_dim, anchors, anchor_mask)\n",
    "    pred_boxes, pred_scores, pred_labels = get_all_yolo_pred(batch_outputs, yolo_anchors, yolo_classes, (target_size[1], target_size[2]))\n",
    "    boxes, scores, labels = calc_nms_box(pred_boxes, pred_scores, pred_labels, valid_thresh, nms_threshold)\n",
    "    boxes = rescale_box_in_input_image(boxes, [input_h, input_w], target_size[1])\n",
    "    print(\"result boxes: \", boxes)\n",
    "    print(\"result scores:\", scores)\n",
    "    print(\"result labels:\", labels)\n",
    "    last_dot_index = image_path.rfind('.')\n",
    "    out_path = image_path[:last_dot_index]\n",
    "    out_path += '-reslut.jpg'\n",
    "    draw_bbox_image(origin, boxes, labels, out_path)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # image_path = sys.argv[1]\n",
    "    image_path = 'data/data6045/lslm-test/5.jpg'\n",
    "    infer(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
